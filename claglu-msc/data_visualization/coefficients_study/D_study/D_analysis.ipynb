{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101782c1-5e94-411c-85b1-93c16fc2a332",
   "metadata": {},
   "source": [
    "# This Notebook allows analyzing the computed diffusion Coefficients as well as the `Q` matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7bd60-cd9a-452c-90e2-b2c020eac730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load plotting style\n",
    "sys.path.append('/home/tobiac/polybox/studium/mscThesis/personal_repo/data_visualization/src')\n",
    "from mscPlotting import set_plotting_environment, SizeParams\n",
    "import diffusionCoeffTools as Dtools \n",
    "set_plotting_environment()\n",
    "\n",
    "# Load plot post-processors\n",
    "from mscPlotting import prepare_emittance_plots, prepare_imshow_plots\n",
    "\n",
    "# Lineplot Kwargs specific to the first section of the Notebook\n",
    "lineplot_kwargs_dict = {\n",
    "                   'logx' : True, \n",
    "                   'logy' : True, \n",
    "                   'color' : None}\n",
    "\n",
    "# Where to store figures\n",
    "figure_dir = '/home/tobiac/polybox/studium/mscThesis/personal_repo/report/figures/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c82f02-ad7a-4084-b7fe-6687c9b0b26a",
   "metadata": {},
   "source": [
    "# Langevin Data from DIH (r256, v64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47221912-ef7e-434b-8c3e-b8bbd3d61bb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load $D$ & $Q$ Field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f8900-208b-43b0-9e49-3a4346c6e6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coeffs_dict = {\"D\" : pd.read_csv(\"spectralHessian_hockney/Dfield_it1199.csv\"),\n",
    "               \"Q\" : pd.read_csv(\"spectralHessian_hockney/Qfield_it1199.csv\"),\n",
    "              \"Fd\" : pd.read_csv(\"spectralHessian_hockney/FdNorm_it1199.csv\")}\n",
    "\n",
    "# coeffs_dict = {\"D\" : pd.read_csv(\"spectralHessian_vico/Dfield_it0200.csv\"),\n",
    "#                \"Q\" : pd.read_csv(\"spectralHessian_vico/Qfield_it1199.csv\"),\n",
    "#               \"Fd\" : pd.read_csv(\"spectralHessian_vico/FdNorm_it1199.csv\")}\n",
    "\n",
    "# coeffs_dict = {\"D\" : pd.read_csv(\"FDhessian_vico/Dfield_it0200.csv\"),\n",
    "#                \"Q\" : pd.read_csv(\"FDhessian_vico/Qfield_it1199.csv\"),\n",
    "#               \"Fd\" : pd.read_csv(\"FDhessian_vico/FdNorm_it1199.csv\")}\n",
    "\n",
    "# coeffs_dict = {\"D\" : pd.read_csv(\"spectralHessian_vico_noVelspaceNorm/Dfield_it1199.csv\"),\n",
    "#                \"Q\" : pd.read_csv(\"spectralHessian_vico_noVelspaceNorm/Qfield_it1199.csv\"),\n",
    "#               \"Fd\" : pd.read_csv(\"spectralHessian_vico_noVelspaceNorm/FdNorm_it1199.csv\")}\n",
    "\n",
    "# Prepend velocity column to `D` and 'Q` dataframes\n",
    "coeffs_dict['D'].insert(0, 'v', coeffs_dict['Fd']['v'])\n",
    "coeffs_dict['Q'].insert(0, 'v', coeffs_dict['Fd']['v'])\n",
    "\n",
    "# Split into center domain and boundary values\n",
    "D_center, D_bdry = Dtools.split_domains(coeffs_dict['D'])\n",
    "coeffs_dict['D Center'] = D_center\n",
    "coeffs_dict['D Boundary'] = D_bdry\n",
    "\n",
    "Q_center, Q_bdry = Dtools.split_domains(coeffs_dict['Q'])\n",
    "coeffs_dict['Q Center'] = Q_center\n",
    "coeffs_dict['Q Boundary'] = Q_bdry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909fbb96-07b5-4443-bf58-63668af867b0",
   "metadata": {},
   "source": [
    "### Distribution of field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d982c-d635-4719-b82b-0a8ed49abda6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "marker_size = 0.05\n",
    "\n",
    "coeffs_dict['D Center'].iloc[::5,:].plot('v', 'D0_y', kind='scatter', logx=False, logy=True, color='red', s=marker_size, ax=ax)\n",
    "coeffs_dict['D Boundary'].iloc[::5,:].plot('v', 'D0_y', kind='scatter', logx=False, logy=True, color='blue', s=marker_size, ax=ax)\n",
    "\n",
    "label_fontsize = 16\n",
    "tick_size = 14\n",
    "\n",
    "plt.xlabel(r'${\\| v \\|}_2$', fontsize=label_fontsize)\n",
    "plt.ylabel(r'$\\boldsymbol{D}_{xy}$', fontsize=label_fontsize)\n",
    "ax.tick_params(axis='both', labelsize=tick_size)\n",
    "plt.legend([r'$\\boldsymbol{D}_{\\Omega}$', r'$\\boldsymbol{D}_{\\partial \\Omega}$'], fontsize=14, markerscale=20)\n",
    "plt.grid()\n",
    "# plt.savefig('../../langevin_study/figures/pre_ippl_meetings/2305/Dxy_maxwellian.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efa061-f67d-487e-a647-4d53a2514f50",
   "metadata": {},
   "source": [
    "### Histogram over $v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80ea5f-b3e5-4f65-b586-94485450bb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coeffs_dict['D'].hist(column='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410b8f2-5fae-49d7-a3bf-795bb146a866",
   "metadata": {},
   "source": [
    "## Averaged Diffusion coefficient over each velocity bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399da44-bbff-4c79-a44c-71ac3d9c2c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dnorm_avg_dict = {}\n",
    "for key, D_df in coeffs_dict.items():\n",
    "    Dnorm_avg_dict[key] = D_df.groupby('v').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670c648-56e0-4b6d-acdd-357b5c281f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_fontsize = 16\n",
    "tick_size = 12\n",
    "title_size = 17\n",
    "\n",
    "logx = False\n",
    "logy = False\n",
    "\n",
    "sharex = True\n",
    "sharey = True\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(12, 4), sharex=sharex, sharey=sharey)\n",
    "\n",
    "matrix_el = 'D0_x'\n",
    "y_axis_label = r'$\\boldsymbol{D}_{xz}$'\n",
    "\n",
    "plot_kind = 'scatter'\n",
    "\n",
    "Dnorm_avg_dict['D Center'].plot('v', matrix_el, use_index=True, kind=plot_kind, logx=logx, logy=logy, color='blue', s=0.5, ax=axes[0])\n",
    "axes[0].set_xlabel(r'${\\| v \\|}_2$', fontsize=label_fontsize)\n",
    "axes[0].set_ylabel(y_axis_label, fontsize=label_fontsize)\n",
    "axes[0].set_title(r'$\\Omega$', fontsize=title_size)\n",
    "\n",
    "Dnorm_avg_dict['D Boundary'].plot('v', matrix_el, use_index=True, kind=plot_kind, logx=logx, logy=logy, color='grey', s=0.5, ax=axes[1])\n",
    "axes[1].set_xlabel(r'${\\| v \\|}_2$', fontsize=label_fontsize)\n",
    "axes[1].set_ylabel(r'')\n",
    "axes[1].set_title(r'$\\partial \\Omega$', fontsize=title_size)\n",
    "\n",
    "Dnorm_avg_dict['D Center'].plot('v', matrix_el, use_index=True, kind=plot_kind, logx=logx, logy=logy, color='blue', s=0.5, ax=axes[2])\n",
    "Dnorm_avg_dict['D Boundary'].plot('v', matrix_el, use_index=True, kind=plot_kind, logx=logx, logy=logy, color='grey', s=0.5, ax=axes[2])\n",
    "axes[2].set_xlabel(r'${\\| v \\|}_2$', fontsize=label_fontsize)\n",
    "axes[2].set_ylabel(r'')\n",
    "axes[2].set_title(r'$\\Omega \\cup \\partial \\Omega$', fontsize=title_size)\n",
    "\n",
    "for ax_el in axes:\n",
    "    ax_el.legend().set_visible(False)\n",
    "    ax_el.grid(True)\n",
    "    ax_el.tick_params(axis='both', labelsize=tick_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('../../langevin_study/figures/pre_ippl_meetings/2305/Dxz_avg_maxwellian.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4ba07-57e6-4d49-9147-4037cd352d17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plots for thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6c23c-5f80-4b1a-a0e6-81247d8797bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure_dir = 'D_figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfdc56-8966-41c7-9289-e5681c6e77f9",
   "metadata": {},
   "source": [
    "## Distribution of $\\boldsymbol D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4393b87-a44d-4468-9e50-486fded6341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load plotting style\n",
    "sys.path.append('/home/tobiac/polybox/studium/mscThesis/personal_repo/data_visualization/src')\n",
    "from mscPlotting import SizeParams\n",
    "set_plotting_environment()\n",
    "\n",
    "# Load convergence plot tools\n",
    "from mscPlotting import prepare_asymptotic_plots\n",
    "\n",
    "# Lineplot Kwargs specific to this section of the Notebook\n",
    "lineplot_kwargs_dict = {\n",
    "                   'logx' : False, \n",
    "                   'logy' : False, \n",
    "                   'color' : None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d7386-0386-4427-8b0f-6455457961c0",
   "metadata": {},
   "source": [
    "## Cholesky Test of dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d2d08-ce51-4cd1-81ab-c095097029e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Working on `coeffs_dict` previously loaded, containing all coefficients (Fd, D, Q)\n",
    "coeffs_dict.keys()\n",
    "coeffs_dict['D Center'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ed4cc-7517-4718-b09b-d1724a1befea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gather vectors and matrices as numpy arrays\n",
    "Fd_vectors = Dtools.extract_coeffs(coeffs_dict['Fd'])\n",
    "D_matrices = Dtools.extract_coeffs(coeffs_dict['D Center'].iloc[:,-9:])\n",
    "Q_matrices = Dtools.extract_coeffs(coeffs_dict['Q Center'].iloc[:,-9:])\n",
    "\n",
    "D_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160e130-1c86-404f-a181-5ca78cf5662d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checks if matrices are positive-definite and symmetric (precondition for valid cholesky decomposition)\n",
    "# Returns numpy and custom cholesky matrices of input matrices\n",
    "# hessian_matrices.shape == (B,N,N)\n",
    "def cholesky_test(hessian_matrices, Q_reference_matrices, error_limit=20):\n",
    "    inp_shape = hessian_matrices.shape\n",
    "    assert len(inp_shape) == 3 and inp_shape[1] == inp_shape[2]\n",
    "    \n",
    "    np_cholesky = []\n",
    "    valid_indices = []\n",
    "    matrices_not_pd = []\n",
    "    matrices_not_semi_pd = []\n",
    "    \n",
    "    Q_relative_error = np.zeros_like(hessian_matrices[0])\n",
    "    \n",
    "    caught_errors = 0\n",
    "    for idx, (D_matrix, Q_matrix) in enumerate(zip(hessian_matrices, Q_reference_matrices)):\n",
    "        # Check for semi-positive-definitness of matrix\n",
    "        e_vals, _ = np.linalg.eig(D_matrix)\n",
    "        if e_vals.all() < 0.0:\n",
    "            matrices_not_semi_pd.append(D_matrix)\n",
    "            \n",
    "        try:        \n",
    "            # Compute Cholesky with two different methods\n",
    "            Lt, Diag, _ = scipy.linalg.ldl(D_matrix)\n",
    "            true_Q = np.sqrt(Diag)*Lt\n",
    "            \n",
    "            # true_Q = apply_LDLt_cholesky3x3(D_matrix)\n",
    "            \n",
    "            D_matrix = np.diag(np.diag(D_matrix))\n",
    "            Lt, Diag, _ = scipy.linalg.ldl(D_matrix)\n",
    "            true_Q = np.sqrt(Diag)*Lt\n",
    "            \n",
    "            np_cholesky.append(true_Q)\n",
    "\n",
    "            valid_indices.append(idx)\n",
    "\n",
    "        except Exception as err:\n",
    "            if caught_errors < error_limit:\n",
    "                print(f'> At idx={idx}: {err}.')\n",
    "            else:\n",
    "                np_cholesky = np.array(np_cholesky)\n",
    "                valid_indices = np.array(valid_indices)\n",
    "                matrices_not_pd = np.array(matrices_not_pd)\n",
    "                return valid_indices, np_cholesky, matrices_not_pd\n",
    "            caught_errors += 1\n",
    "\n",
    "    np_cholesky = np.array(np_cholesky)\n",
    "    valid_indices = np.array(valid_indices)\n",
    "    matrices_not_pd = np.array(matrices_not_pd)\n",
    "\n",
    "    # Check if Cholesky decompositions coincide\n",
    "    total_error = np.zeros_like(hessian_matrices[0,...])\n",
    "    cholesky_error_matrices = np.zeros_like(hessian_matrices)\n",
    "\n",
    "    print(f'==================================================================')\n",
    "    print(f'Encountered {caught_errors} errors when computing the Cholesky-Decomposition.')\n",
    "    print(f'{len(matrices_not_semi_pd)}/{hessian_matrices.shape[0]} matrices are negative definite!')\n",
    "    print(f'{np_cholesky.shape[0]}/{hessian_matrices.shape[0]} matrices are positive definite!')\n",
    "    \n",
    "    print('Error matrix per element:')\n",
    "    print(total_error/np_cholesky.shape[0])\n",
    "\n",
    "    return valid_indices, np_cholesky, matrices_not_pd, cholesky_error_matrices, total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2e5c6-a9b2-4028-918f-d137c4842c5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_indices, np_cholesky, matrices_not_pd = cholesky_test(D_matrices, Q_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278c80e-a76e-475a-aca1-c1ea3ee4af21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Some matrices are indeed negative definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8703e-497a-444b-a233-57daca060f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_vals, _ = np.linalg.eig(D_matrices[2])\n",
    "e_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28a795-9a08-4f86-baba-d5c53a1cc54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Lt, Diag, _ = scipy.linalg.ldl(D_matrices[2])\n",
    "print(f'Lt:\\n{Lt}\\nDiag:\\n{Diag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f4444-6f6a-4fe2-945e-918d618a2c0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Our computation of Q requires the sqrt. Thus it fails for negative definite matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048b740-449f-42cb-9d98-ec1628f480ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_Q = Dtools.apply_LDLt_cholesky3x3(D_matrices[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf0f62-9de9-43a3-b602-18c56270c3c0",
   "metadata": {},
   "source": [
    "# Create encoded cube slice determining matrix type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f44655-cbce-4b26-9118-fa705b2da6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given cube of size [N^3, M, M] returns [N^2, M, M] at given idx along z axis\n",
    "def create_cube_zslice(matrix_cube, idx=None):\n",
    "    N3 = matrix_cube.shape[0]\n",
    "    trailing_axes_size = matrix_cube.shape[1:]\n",
    "    N = int((N3+1)**(1.0/3.0))\n",
    "\n",
    "    if idx is None:\n",
    "        idx = N//2\n",
    "\n",
    "    return matrix_cube.reshape(N,N,N,*trailing_axes_size)[:,:,idx,...].reshape(N*N,-1), N\n",
    "\n",
    "# Input shape: (N^3,M,M)\n",
    "def create_encoded_slice(cube_field):\n",
    "    cube_slice, M = create_cube_zslice(cube_field)\n",
    "    \n",
    "    # Create output matrix with scalars as fields (same size as `cube_slice`)\n",
    "    output_encoding = np.zeros(cube_slice.shape[0], dtype=np.int8)\n",
    "    \n",
    "    # Loop through entries\n",
    "    for idx in range(cube_slice.shape[0]):\n",
    "        # Compute eigendecomposition\n",
    "        e_vals, _ = np.linalg.eig(cube_slice[idx].reshape(3,3))\n",
    "        \n",
    "        # Assign label according to property\n",
    "        if np.any(e_vals < 0): # negative\n",
    "            if np.all(e_vals < 0):\n",
    "                output_encoding[idx] = 0 # negative definite\n",
    "            else:\n",
    "                output_encoding[idx] = 1 # negative semi-definite\n",
    "        else:\n",
    "            if np.all(e_vals > 0):\n",
    "                output_encoding[idx] = 3 # positive definite\n",
    "            else:\n",
    "                output_encoding[idx] = 2 # positive semi-definite\n",
    "    \n",
    "    return output_encoding.reshape(M,M)\n",
    "\n",
    "def plot_encoded_slice(encoded_data, ax, plot_legend=False, vmax=5e7):\n",
    "    \n",
    "    # Create colormap containing a color for each possible value in the data\n",
    "    colormap = ListedColormap(sns.color_palette(\"colorblind\").as_hex(), N=4)\n",
    "    cmap_list = [colormap(i) for i in range(colormap.N)]\n",
    "    # Rotate colormap by one element (results in nicer color combinations for values {1,3})\n",
    "    cmap_list = cmap_list[1:] + cmap_list[:1]\n",
    "\n",
    "    labels = ['negative-definite', 'negative semi-definite', 'positive semi-definite', 'positive-definite']\n",
    "\n",
    "    # Remove labels that are not present in data\n",
    "    removed_els = 0\n",
    "    for i in range(len(cmap_list)):\n",
    "        if np.sum(encoded_data == i) == 0:\n",
    "            del cmap_list[i - removed_els]\n",
    "            del labels[i - removed_els]\n",
    "            removed_els += 1\n",
    "\n",
    "    # Generate new colormap only containing existing values\n",
    "    cmap = ListedColormap(cmap_list)\n",
    "\n",
    "    # Create a patch (proxy artist) for every color\n",
    "    patches = [ mpatches.Patch(color=cmap_list[i], label=f'{labels[i]}') for i in range(len(cmap_list)) ]\n",
    "    \n",
    "    if plot_legend == True:\n",
    "        # Put those patched as legend-handles into the legend\n",
    "        ax.legend(handles=patches, loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, fontsize=SizeParams().ticksize)\n",
    "\n",
    "    \n",
    "    ax.imshow(encoded_data, cmap=cmap, extent=[-vmax,vmax,-vmax,vmax])\n",
    "    ax.grid()\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0483226-02ab-460b-b2d4-47ce2155f18b",
   "metadata": {},
   "source": [
    "## Hessian over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696d137-d839-4b6b-88f8-00999fe22002",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dfield_keys = ['0400', '0600', '0800', '0999']\n",
    "file_pattern = 'langevin_Danalysis_0713_0833/Dfield_it'\n",
    "\n",
    "num_axes = len(Dfield_keys)\n",
    "fig, axes = plt.subplots(1, num_axes, figsize=(num_axes*5, 5), sharey=True)\n",
    "\n",
    "coeffs_dict = {}\n",
    "\n",
    "for (Dkey, ax) in zip(Dfield_keys, axes):\n",
    "    # Load data, take center domain, extract matrix format entries, classify matrices with label\n",
    "    coeffs_dict[Dkey] = Dtools.create_encoded_slice(Dtools.extract_coeffs(Dtools.split_domains(pd.read_csv(f'{file_pattern}{Dkey}.csv'))[0]))\n",
    "    patches_for_label = Dtools.plot_encoded_slice(coeffs_dict[Dkey], ax)\n",
    "    \n",
    "    time_str = f'{Dkey.lstrip(\"0\")}'\n",
    "    ax.set_title(r'$t\\ =\\ $' + f'{Dkey.lstrip(\"0\")}' + r'$dt$', y=1.05, fontsize=SizeParams().label_fontsize)\n",
    "    \n",
    "    x_label = r'$\\boldsymbol v_x$'\n",
    "    y_label = ''\n",
    "    \n",
    "fig.legend(handles=patches_for_label, loc='upper center', bbox_to_anchor=(0.5, -0.03), fancybox=True, shadow=True, fontsize=SizeParams().ticksize)\n",
    "\n",
    "# Put ylabel on first plot only\n",
    "y_label = r'$\\boldsymbol v_y$'\n",
    "axes[0].set_ylabel(y_label)\n",
    "\n",
    "# fig.savefig(figure_dir+f'/D_cholesky_time.pdf', bbox_inches = \"tight\"),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e9c9c-d4e0-4396-ab20-2cfd338ded6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hessian type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d69fef-0165-496d-811a-93cf7c977c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dfield_keys = ['FDhessian_hockney/Dfield_it1000.csv',\n",
    "              'FDhessian_vico/Dfield_it1000.csv',\n",
    "              'spectralHessian_hockney/Dfield_it1000.csv',\n",
    "              'spectralHessian_vico/Dfield_it1000.csv']\n",
    "\n",
    "axes_titles = [r'FD $H_g$ (Hockney)',\n",
    "              r'FD $H_g$ (Vico)',\n",
    "              r'Spectral $H_g$ (Hockney)',\n",
    "              r'Spectral $H_g$ (Vico)']\n",
    "\n",
    "num_axes = len(Dfield_keys)\n",
    "fig, axes = plt.subplots(1, num_axes, figsize=(num_axes*5, 5), sharey=True)\n",
    "\n",
    "coeffs_dict = {}\n",
    "\n",
    "for (Dkey, ax, ax_title) in zip(Dfield_keys, axes, axes_titles):\n",
    "    coeffs_dict[Dkey] = Dtools.create_encoded_slice(Dtools.extract_coeffs(Dtools.split_domains(pd.read_csv(f'{Dkey}'))[0]))\n",
    "    patches_for_label = Dtools.plot_encoded_slice(coeffs_dict[Dkey], ax)\n",
    "    \n",
    "    ax.set_title(ax_title, y=1.05, fontsize=SizeParams().label_fontsize)\n",
    "\n",
    "fig.legend(handles=patches_for_label, loc='upper center', bbox_to_anchor=(0.5, 0.05), fancybox=True, shadow=True, fontsize=SizeParams().ticksize)\n",
    "\n",
    "# fig.savefig(figure_dir+f'/hessian_comparison.pdf', bbox_inches = \"tight\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2562e-8219-4e46-96d8-ef1e7e8de5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_matrices = Dtools.extract_coeffs(Dtools.split_domains(pd.read_csv(f'../../langevin_study/langevin_data/submission_data/langevin_P3M_Fd_D_r256_v64_vico_0712_1412/Dfield_it1199.csv'))[0])\n",
    "\n",
    "test_matrix1 = test_matrices[0]\n",
    "test_matrix2 = test_matrices[1]\n",
    "\n",
    "print(f'1: {test_matrix1}\\n')\n",
    "print(f'2: {test_matrix2}\\n')\n",
    "\n",
    "\n",
    "# Set off-diagonals to zero:\n",
    "# test_matrix[test_matrix < 1e-14] = 0.0\n",
    "\n",
    "e_vals, _ = np.linalg.eig(test_matrix1)\n",
    "print(f'Evals = {e_vals}\\n')\n",
    "print(f'{test_matrix1}\\n')\n",
    "print(f'{Dtools.apply_LDLt_cholesky3x3_safe(test_matrix1)}')\n",
    "\n",
    "print(f'{Dtools.apply_LDLt_cholesky3x3_numpy(np.diag(np.diag(test_matrix1)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bcf1d-7016-46b4-b7fd-6c28b4e86211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "patches_for_label = Dtools.plot_encoded_slice(Dtools.create_encoded_slice(Dtools.extract_coeffs(Dtools.split_domains(pd.read_csv('langevin_Danalysis_0713_0833/Dfield_it0800.csv'))[0])), ax)\n",
    "\n",
    "# patches_for_label = plot_encoded_slice(create_encoded_slice(extract_coeffs(split_domains(pd.read_csv(f'../../langevin_study/langevin_data/submission_data/langevin_P3M_Fd_D_r256_v64_vico_0712_1412/Dfield_it1199.csv'))[0])), ax)\n",
    "\n",
    "fig.legend(handles=patches_for_label, loc='upper center', bbox_to_anchor=(0.5, 1.1), fancybox=True, shadow=True, fontsize=SizeParams().ticksize)\n",
    "\n",
    "# fig.savefig('/home/tobiac/polybox/studium/mscThesis/personal_repo/presentations/langevin_discussions/0711/hessian_comparison.pdf', bbox_inches = \"tight\"),\n",
    "\n",
    "x_label = r'$\\boldsymbol v_x$'\n",
    "y_label = r'$\\boldsymbol v_y$'\n",
    "\n",
    "prepare_imshow_plots(ax, x_label, y_label, legend_loc='right', bbox_to_anchor=None, ncol=1)\n",
    "\n",
    "# fig.savefig(figure_dir+f'/D_cholesky_it0800.pdf', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d63a94-c10e-4752-8618-fc3ac195b58e",
   "metadata": {},
   "source": [
    "## Test that our LDLT decomposition works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a02af2-dc1d-42a9-977d-71f7e6685efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For any matrix A, A*A^T is positive semi-definite\n",
    "def make_spd_matrix(dim=3):\n",
    "    mat = np.random.rand(dim,dim)\n",
    "    return np.dot(mat, mat.transpose())\n",
    "\n",
    "# Create spd matrix that has a large condition number (|\\lambda_{max}|/|\\lambda_{min}| >> 0)\n",
    "def make_hard_spd_matrix(dim=3, condition_number_magnitude=1e8):\n",
    "    eigenvalues = np.diag(np.random.rand(dim))\n",
    "    # Scale a random eigenvalue\n",
    "    rand_idx = np.random.randint(1)\n",
    "    eigenvalues[rand_idx, rand_idx] *= condition_number_magnitude\n",
    "    \n",
    "    eigenvalues = np.sqrt(eigenvalues)\n",
    "\n",
    "    R = np.random.rand(dim,dim)\n",
    "\n",
    "    return np.dot(np.dot(np.dot(R, eigenvalues), eigenvalues), R.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40587f2b-3a46-4747-8553-444a106a0af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate random SPD matrices\n",
    "N_spd_matrices = 10000\n",
    "\n",
    "spd_matrices = np.array([make_hard_spd_matrix(3) for i in range(N_spd_matrices)])\n",
    "\n",
    "error_limit = 10\n",
    "incorrectly_decomposed = []\n",
    "\n",
    "for idx, spd_matrix in enumerate(spd_matrices):\n",
    "    caught_errors = 0\n",
    "    try:\n",
    "        Q = Dtools.apply_LDLt_cholesky3x3(spd_matrix)\n",
    "        \n",
    "    except Exception as err:\n",
    "        incorrectly_decomposed.append(spd_matrix)\n",
    "        if caught_errors < error_limit:\n",
    "            print(f'> At idx={idx}: {err}.')\n",
    "        caught_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e70f4c-fc4b-4ff2-b871-27a19c39203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(incorrectly_decomposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efda9eb-5f22-4898-a9c2-eca58afe1221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = Dtools.apply_LDLt_cholesky3x3(spd_matrices[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b105e5-efd9-487f-8687-4e86e34769de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_vals, _ = np.linalg.eig(incorrectly_decomposed)\n",
    "e_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ccfc9-cbf5-4560-b967-f43f5f1f468b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "incorrectly_decomposed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
